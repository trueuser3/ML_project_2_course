{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "890AP4C8hBb8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# E - размер входа, H - размер скрытого состояния\n",
        "# B, L - количество примеров и их размер\n",
        "\n",
        "E, H  = 2, 3\n",
        "B, L  = 4, 5\n",
        "\n",
        "rnn = nn.RNN(E, H)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in rnn.state_dict().items():\n",
        "    print(f'{k:10s} : {tuple(v.shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duF4jiuIh6-o",
        "outputId": "4131cb04-4309-4763-cedf-1e33e3a91a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 : (3, 2)\n",
            "weight_hh_l0 : (3, 3)\n",
            "bias_ih_l0 : (3,)\n",
            "bias_hh_l0 : (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X  = torch.rand(L, B, E)\n",
        "Y, Hn = rnn(X)"
      ],
      "metadata": {
        "id": "M38FQBXsh9rM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuple(Y.shape), tuple(Hn.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpKKYvYriJG-",
        "outputId": "3e317994-0b87-4bda-9adf-5bafd2b78921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 4, 3) (1, 4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_ih, W_hh = rnn.weight_ih_l0.detach(), rnn.weight_hh_l0.detach()\n",
        "B_ih, B_hh = rnn.bias_ih_l0.detach(),   rnn.bias_hh_l0.detach()"
      ],
      "metadata": {
        "id": "KTKI8dj-ii6U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hn = torch.zeros(B,H)\n",
        "\n",
        "for x in X:\n",
        "    Hn =torch.tanh(  torch.addmm(B_ih, x,  W_ih.t()) + torch.addmm(B_hh, Hn, W_hh.t()) )\n",
        "    print(Hn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygEdBs2Qi9Jz",
        "outputId": "ee953031-6d84-4803-9ced-a4b741fa6cd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0728, -0.7198, -0.6872],\n",
            "        [-0.0656, -0.7529, -0.6889],\n",
            "        [ 0.0662, -0.7474, -0.5638],\n",
            "        [ 0.1296, -0.7063, -0.4787]])\n",
            "tensor([[-0.4246, -0.6300, -0.2707],\n",
            "        [-0.4110, -0.6244, -0.2025],\n",
            "        [-0.5713, -0.5834, -0.4371],\n",
            "        [-0.4092, -0.4734, -0.1342]])\n",
            "tensor([[ 0.1086, -0.5023, -0.0607],\n",
            "        [-0.2653, -0.6526, -0.6231],\n",
            "        [-0.0191, -0.5722, -0.3650],\n",
            "        [ 0.1580, -0.5413, -0.2267]])\n",
            "tensor([[-0.2583, -0.6758, -0.3980],\n",
            "        [-0.3015, -0.6125, -0.3422],\n",
            "        [-0.4567, -0.7020, -0.5795],\n",
            "        [-0.4640, -0.7354, -0.5554]])\n",
            "tensor([[-0.3943, -0.6587, -0.5607],\n",
            "        [-0.2851, -0.6885, -0.5361],\n",
            "        [-0.1830, -0.5051, -0.2840],\n",
            "        [-0.2347, -0.5927, -0.3677]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hn = torch.zeros(1,B,H)\n",
        "for x in X:\n",
        "    _, Hn = rnn( x.view(1,B,E), Hn )\n",
        "    print(Hn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdWN7tdGjJcl",
        "outputId": "2dae7a69-c1d6-4ff3-b9e3-86f1b2a88160"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0728, -0.7198, -0.6872],\n",
            "         [-0.0656, -0.7529, -0.6889],\n",
            "         [ 0.0662, -0.7474, -0.5638],\n",
            "         [ 0.1296, -0.7063, -0.4787]]], grad_fn=<StackBackward0>)\n",
            "tensor([[[-0.4246, -0.6300, -0.2707],\n",
            "         [-0.4110, -0.6244, -0.2025],\n",
            "         [-0.5713, -0.5834, -0.4371],\n",
            "         [-0.4092, -0.4734, -0.1342]]], grad_fn=<StackBackward0>)\n",
            "tensor([[[ 0.1086, -0.5023, -0.0607],\n",
            "         [-0.2653, -0.6526, -0.6231],\n",
            "         [-0.0191, -0.5722, -0.3650],\n",
            "         [ 0.1580, -0.5413, -0.2267]]], grad_fn=<StackBackward0>)\n",
            "tensor([[[-0.2583, -0.6758, -0.3980],\n",
            "         [-0.3015, -0.6125, -0.3422],\n",
            "         [-0.4567, -0.7020, -0.5795],\n",
            "         [-0.4640, -0.7354, -0.5554]]], grad_fn=<StackBackward0>)\n",
            "tensor([[[-0.3943, -0.6587, -0.5607],\n",
            "         [-0.2851, -0.6885, -0.5361],\n",
            "         [-0.1830, -0.5051, -0.2840],\n",
            "         [-0.2347, -0.5927, -0.3677]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Двунаправленный рекурентный слой и стопка слоёв"
      ],
      "metadata": {
        "id": "7iym690okGWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = nn.RNN(E, H, bidirectional=True)\n",
        "rnn_3 = nn.RNN(E, H, num_layers=3)"
      ],
      "metadata": {
        "id": "1VaQwRLskEMC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmcSq3NVlC_p",
        "outputId": "9fb1625c-bcca-4914-d021-da5b34c88e55"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Линейная модель"
      ],
      "metadata": {
        "id": "HprANT4X5Ezi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as tfs"
      ],
      "metadata": {
        "id": "nA_47qoQlc4N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_tfs = tfs.Compose([\n",
        "  tfs.ToTensor(),\n",
        "  tfs.Normalize((0.5), (0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "KdVY2tFY2uDI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = './'\n",
        "train = MNIST(root, train=True,  transform=data_tfs, download=True)\n",
        "test  = MNIST(root, train=False, transform=data_tfs, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX2oBgc420Xt",
        "outputId": "0cd348be-966d-4506-a264-97ee396c3d62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 5475370.05it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 159650.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1295292.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 733022.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, drop_last=True)"
      ],
      "metadata": {
        "id": "qbP74_2n3H_J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dX9_AiE3DcL",
        "outputId": "45d78f88-3481-49c1-9670-845711f3fe07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = 784\n",
        "classes = 10\n",
        "epochs = 3\n",
        "lr=1e-2\n",
        "history = []"
      ],
      "metadata": {
        "id": "7XM4zBwe0b-w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.FloatTensor(features, classes).uniform_(-1, 1) / features**0.5\n",
        "W.requires_grad_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eOADMuV43J4",
        "outputId": "dc97c31b-7295-4d38-b067-3dbfc058fed9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0031,  0.0236, -0.0060,  ...,  0.0016,  0.0304,  0.0348],\n",
              "        [ 0.0093,  0.0247,  0.0120,  ...,  0.0015, -0.0298,  0.0237],\n",
              "        [ 0.0086, -0.0313,  0.0122,  ..., -0.0357, -0.0111,  0.0093],\n",
              "        ...,\n",
              "        [-0.0088,  0.0068, -0.0233,  ...,  0.0011, -0.0293,  0.0247],\n",
              "        [-0.0251,  0.0241,  0.0074,  ..., -0.0221,  0.0288,  0.0208],\n",
              "        [ 0.0005,  0.0243, -0.0216,  ..., -0.0212,  0.0283, -0.0183]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.nn.functional import cross_entropy"
      ],
      "metadata": {
        "id": "1QcAKtbF4wcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "\n",
        "    x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
        "\n",
        "    logits = x_batch @ W\n",
        "\n",
        "    probabilities = torch.exp(logits) / torch.exp(logits).sum(dim=1, keepdims=True)\n",
        "\n",
        "    loss = -torch.log(probabilities[range(batch_size), y_batch]).mean()\n",
        "    history.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    grad = W.grad\n",
        "    with torch.no_grad():\n",
        "      W -= lr * grad\n",
        "    W.grad.zero_()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qgMzZOG4y3_",
        "outputId": "bc1fd3b8-e15f-40b2-876c-074b2fa3da5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,\t loss: 0.18877600133419037\n",
            "2,\t loss: 0.13609187304973602\n",
            "3,\t loss: 0.11687606573104858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "model = nn.Sequential(\n",
        "  nn.Linear(features, 64),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(64, classes)\n",
        ")"
      ],
      "metadata": {
        "id": "jE_lg46L5QsZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (features,), batch_size=228)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_jZ20la5j-Z",
        "outputId": "08bfa5ca-4c45-476a-8c25-70a3096a325c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [228, 64]          50,240\n",
            "              ReLU-2                  [228, 64]               0\n",
            "            Linear-3                  [228, 10]             650\n",
            "================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.68\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 0.19\n",
            "Estimated Total Size (MB): 1.12\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))"
      ],
      "metadata": {
        "id": "xHl84iKz5qFF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "history = []"
      ],
      "metadata": {
        "id": "Auwdzsms5xcU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.view(x_batch.shape[0], -1)\n",
        "    y_batch = y_batch\n",
        "    logits = model(x_batch)\n",
        "\n",
        "    loss = criterion(logits, y_batch)\n",
        "    history.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB9oZHyz5zfJ",
        "outputId": "694bb37a-139a-4eb9-b59f-fa1fab9558d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,\t loss: 0.1046971008181572\n",
            "2,\t loss: 0.06989177316427231\n",
            "3,\t loss: 0.060989152640104294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация рекурентной нейронной сети"
      ],
      "metadata": {
        "id": "LcquA4CRzbtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_tensor):\n",
        "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
        "\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "metadata": {
        "id": "qpz6gdLKy64G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "learning_rate = 0.005\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "def train(line_tensor, category_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "dsx8qY0Jzq82"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}